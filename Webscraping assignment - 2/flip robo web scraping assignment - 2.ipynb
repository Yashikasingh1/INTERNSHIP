{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b635d73a",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location.  \n",
    "You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 \n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the \n",
    "location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22947bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48513bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\Yashika\\OneDrive\\Desktop\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33dfae3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags = driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "location_tags = driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "company_tags = driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "experience_tags = driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc5fc3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afa6da3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst/Senior Analyst - R/SQL/Python</td>\n",
       "      <td>Temp. WFH - Bangalore/Bengaluru, Kolkata, Mumb...</td>\n",
       "      <td>The Nikharv Consultancy</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Target</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data analyst / data analytics - US MNC (analyt...</td>\n",
       "      <td>Temp. WFH - Bangalore/Bengaluru, Gurgaon/Gurugram</td>\n",
       "      <td>Aspyra Hr Services</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst (Jr/Sr)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Pole To Win (PTW)</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business Data Analyst (Sr Exe / Asst Manager)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Talentleads</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Junior Data Analyst/ Scientist- Fresher Position</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, New Delhi, Mumba...</td>\n",
       "      <td>Sejal Consulting Hub</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analysts - Compliance Surveillance</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru</td>\n",
       "      <td>Standard Chartered Bank</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sr Data Analyst</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru</td>\n",
       "      <td>Amolitalents</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Job Opportunity with Leading MNC - Senior Data...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Enrich And Enlight Business Consulting</td>\n",
       "      <td>5-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Manager/Senior Manager - Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>Huquo Consulting Pvt. Ltd</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0         Data Analyst/Senior Analyst - R/SQL/Python   \n",
       "1                                       Data Analyst   \n",
       "2  data analyst / data analytics - US MNC (analyt...   \n",
       "3                               Data Analyst (Jr/Sr)   \n",
       "4      Business Data Analyst (Sr Exe / Asst Manager)   \n",
       "5   Junior Data Analyst/ Scientist- Fresher Position   \n",
       "6            Data Analysts - Compliance Surveillance   \n",
       "7                                    Sr Data Analyst   \n",
       "8  Job Opportunity with Leading MNC - Senior Data...   \n",
       "9              Manager/Senior Manager - Data Analyst   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Temp. WFH - Bangalore/Bengaluru, Kolkata, Mumb...   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2  Temp. WFH - Bangalore/Bengaluru, Gurgaon/Gurugram   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5  Hybrid - Bangalore/Bengaluru, New Delhi, Mumba...   \n",
       "6                       Hybrid - Bangalore/Bengaluru   \n",
       "7                       Hybrid - Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...   \n",
       "\n",
       "                             Company_name Experience  \n",
       "0                 The Nikharv Consultancy    3-6 Yrs  \n",
       "1                                  Target    2-4 Yrs  \n",
       "2                      Aspyra Hr Services    3-8 Yrs  \n",
       "3                       Pole To Win (PTW)    1-4 Yrs  \n",
       "4                             Talentleads    3-5 Yrs  \n",
       "5                    Sejal Consulting Hub    0-5 Yrs  \n",
       "6                 Standard Chartered Bank    4-9 Yrs  \n",
       "7                            Amolitalents    6-9 Yrs  \n",
       "8  Enrich And Enlight Business Consulting    5-7 Yrs  \n",
       "9               Huquo Consulting Pvt. Ltd    2-7 Yrs  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Title': job_title,'Location': job_location,'Company_name':company_name,'Experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63523aba",
   "metadata": {},
   "source": [
    "# Question - 2 Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. \n",
    "You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the \n",
    "location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results youget.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09701341",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\Yashika\\OneDrive\\Desktop\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f937bd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "721a7a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32106835",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80ee7fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0b231e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fe9b53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags = driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "location_tags = driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "company_tags = driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "experience_tags = driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af60b78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cdac5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Kolkata, Mumbai, H...</td>\n",
       "      <td>Capgemini</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Temp. WFH - Bangalore/Bengaluru, Hyderabad/Sec...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>Birlasoft</td>\n",
       "      <td>8-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Noida, Hyderabad...</td>\n",
       "      <td>Birlasoft</td>\n",
       "      <td>8-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist Knowledge graph</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Pune</td>\n",
       "      <td>Capco</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Infosys</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Supply Chain Specialist Staff</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Juniper Networks</td>\n",
       "      <td>7-11 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Title  \\\n",
       "0                    Data Scientist   \n",
       "1                    Data Scientist   \n",
       "2           Data Science Specialist   \n",
       "3  Analystics & Modeling Specialist   \n",
       "4               Lead Data Scientist   \n",
       "5                    Data Scientist   \n",
       "6                    Data Scientist   \n",
       "7    Data Scientist Knowledge graph   \n",
       "8                    Data Scientist   \n",
       "9     Supply Chain Specialist Staff   \n",
       "\n",
       "                                            Location      Company_name  \\\n",
       "0  Bangalore/Bengaluru, Noida, Kolkata, Mumbai, H...         Capgemini   \n",
       "1  Temp. WFH - Bangalore/Bengaluru, Hyderabad/Sec...     Tech Mahindra   \n",
       "2  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...         Accenture   \n",
       "3  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...         Accenture   \n",
       "4  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...         Birlasoft   \n",
       "5  Hybrid - Bangalore/Bengaluru, Noida, Hyderabad...         Birlasoft   \n",
       "6                                Bangalore/Bengaluru               ANZ   \n",
       "7                 Hybrid - Bangalore/Bengaluru, Pune             Capco   \n",
       "8                                Bangalore/Bengaluru           Infosys   \n",
       "9                                Bangalore/Bengaluru  Juniper Networks   \n",
       "\n",
       "  Experience  \n",
       "0   9-14 Yrs  \n",
       "1   7-12 Yrs  \n",
       "2    2-4 Yrs  \n",
       "3    6-8 Yrs  \n",
       "4   8-12 Yrs  \n",
       "5   8-12 Yrs  \n",
       "6    2-7 Yrs  \n",
       "7   7-12 Yrs  \n",
       "8    3-5 Yrs  \n",
       "9   7-11 Yrs  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Title': job_title,'Location': job_location,'Company_name':company_name,'Experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef5670c",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results. \n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get thewebpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results youget.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "364782f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\Yashika\\OneDrive\\Desktop\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b60a956",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f67990f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f92e0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1174a14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_sal_btn = driver.find_element(By.XPATH,\"//span[@title='3-6 Lakhs']\")\n",
    "filter_sal_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f24629fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_btn = driver.find_elements(By.XPATH,\"//span[@title='Delhi / NCR']\")\n",
    "for i in filter_btn:\n",
    "    if i.text =='Delhi / NCR':\n",
    "        i.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "146f58d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []\n",
    "salary_required = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ba189af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags = driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "location_tags = driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "company_tags = driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "experience_tags = driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)\n",
    "    \n",
    "salary_tags = driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft \"]')\n",
    "for i in salary_tags[0:10]:\n",
    "    salary=i.text\n",
    "    salary_required.append(salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5d6f1752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required),len(salary_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "541897a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analyst-Data Science</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>AMERICAN EXPRESS</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analyst-Data Science</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>AMERICAN EXPRESS</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi / NCR, Noida(Sector-136 Noida), Ghaziaba...</td>\n",
       "      <td>Extramarks Education</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>5,00,000 - 15,00,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Gujarat Fluorochemicals</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AWS Data Warehouse Developer - IT Industry</td>\n",
       "      <td>Delhi / NCR, Bangalore/Bengaluru, Maharashtra</td>\n",
       "      <td>GenNext India Private Limited</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>5,00,000 - 10,00,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Permanent Remote</td>\n",
       "      <td>Vizlogic Digital Solutions</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>4,00,000 - 6,00,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Metrix Research &amp; Analytics</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Dehradun, Hyderabad/Secunderabad, Gurgaon/Guru...</td>\n",
       "      <td>torcai digital media</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>Skyleaf Consultants</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>4,00,000 - 9,00,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Modeler</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Resource Access Management Solutions Pvt. Ltd.</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Title  \\\n",
       "0                        Analyst-Data Science   \n",
       "1                        Analyst-Data Science   \n",
       "2                              Data Scientist   \n",
       "3                              Data Scientist   \n",
       "4  AWS Data Warehouse Developer - IT Industry   \n",
       "5                              Data Scientist   \n",
       "6                              Data Scientist   \n",
       "7                              Data Scientist   \n",
       "8                       Junior Data Scientist   \n",
       "9                                     Modeler   \n",
       "\n",
       "                                            Location  \\\n",
       "0                                   Gurgaon/Gurugram   \n",
       "1                                   Gurgaon/Gurugram   \n",
       "2  Delhi / NCR, Noida(Sector-136 Noida), Ghaziaba...   \n",
       "3                                              Noida   \n",
       "4      Delhi / NCR, Bangalore/Bengaluru, Maharashtra   \n",
       "5                                   Permanent Remote   \n",
       "6                                              Noida   \n",
       "7  Dehradun, Hyderabad/Secunderabad, Gurgaon/Guru...   \n",
       "8                                        Delhi / NCR   \n",
       "9                                              Noida   \n",
       "\n",
       "                                     Company_name Experience  \\\n",
       "0                                AMERICAN EXPRESS    0-3 Yrs   \n",
       "1                                AMERICAN EXPRESS    0-3 Yrs   \n",
       "2                            Extramarks Education    3-5 Yrs   \n",
       "3                         Gujarat Fluorochemicals    1-2 Yrs   \n",
       "4                   GenNext India Private Limited    4-9 Yrs   \n",
       "5                      Vizlogic Digital Solutions    2-5 Yrs   \n",
       "6                     Metrix Research & Analytics    3-7 Yrs   \n",
       "7                            torcai digital media    2-7 Yrs   \n",
       "8                             Skyleaf Consultants    2-4 Yrs   \n",
       "9  Resource Access Management Solutions Pvt. Ltd.    3-7 Yrs   \n",
       "\n",
       "                     salary  \n",
       "0             Not disclosed  \n",
       "1             Not disclosed  \n",
       "2  5,00,000 - 15,00,000 PA.  \n",
       "3             Not disclosed  \n",
       "4  5,00,000 - 10,00,000 PA.  \n",
       "5   4,00,000 - 6,00,000 PA.  \n",
       "6             Not disclosed  \n",
       "7             Not disclosed  \n",
       "8   4,00,000 - 9,00,000 PA.  \n",
       "9             Not disclosed  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Title': job_title,'Location': job_location,'Company_name':company_name,'Experience':experience_required, 'salary':salary_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1677d264",
   "metadata": {},
   "source": [
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url :https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and \n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the \n",
    "required data asusual.\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then\n",
    "click on it.\n",
    "5. Now scrape data from this page asusual\n",
    "6. Repeat this until you get data for 100sunglasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "131efd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\Yashika\\OneDrive\\Desktop\\chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "\n",
    "designation = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "designation.send_keys('sunglasses')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f9c1f616",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1526f84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "Brand_titles = []\n",
    "Product_Description = []\n",
    "Price_range = []\n",
    "\n",
    "start = 0\n",
    "end = 3\n",
    "\n",
    "for page in range(start,end):\n",
    "    titles = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    descriptions = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    prices = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    min_length = min(len(titles), len(descriptions), len(prices))\n",
    "    for i in range(min_length):\n",
    "        Brand_titles.append(titles[i].text)\n",
    "        Product_Description.append(descriptions[i].text)\n",
    "        Price_range.append(prices[i].text)\n",
    "    try:\n",
    "        next_button = driver.find_elements(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "        next_button[0].click()\n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        break\n",
    "    if len(Brand_titles)>=100:\n",
    "        break\n",
    "Brand_titles = Brand_titles[:100]\n",
    "Product_Description = Product_Description[:100]\n",
    "Price_range = Price_range[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e1ad2b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand_titles), len(Product_Description), len(Price_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "077125a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>₹398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Resist</td>\n",
       "      <td>Polarized Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹1,399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Cat-eye, Retro Square, Oval, Rou...</td>\n",
       "      <td>₹149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (52)</td>\n",
       "      <td>₹182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Eyewearlabs</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹1,519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (50)</td>\n",
       "      <td>₹149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>New Specs</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Title                                        Description   Price\n",
       "0   ROZZETTA CRAFT  UV Protection, Gradient Rectangular Sunglasses...    ₹398\n",
       "1           Resist          Polarized Wayfarer Sunglasses (Free Size)  ₹1,399\n",
       "2         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)    ₹599\n",
       "3        Elligator  UV Protection Cat-eye, Retro Square, Oval, Rou...    ₹149\n",
       "4         Fastrack   UV Protection Rectangular Sunglasses (Free Size)    ₹499\n",
       "..             ...                                                ...     ...\n",
       "95          PIRASO          UV Protection Rectangular Sunglasses (52)    ₹182\n",
       "96     Eyewearlabs     Polarized, UV Protection Round Sunglasses (54)  ₹1,519\n",
       "97            SRPM             UV Protection Wayfarer Sunglasses (50)    ₹149\n",
       "98       New Specs   UV Protection Rectangular Sunglasses (Free Size)    ₹259\n",
       "99        Fastrack  Gradient, UV Protection Wayfarer Sunglasses (F...    ₹579\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Title': Brand_titles,'Description': Product_Description,'Price': Price_range})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5dc135",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. \n",
    "You have to go the link: \n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100reviews.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e490a837",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\Yashika\\OneDrive\\Desktop\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "bad4de90",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "681b7a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating = []\n",
    "Review_summary  = []\n",
    "Full_review = []\n",
    "\n",
    "for i in range(1,20):\n",
    "    \n",
    "    for i in driver.find_elements(By.XPATH,\"//div[@class='_3LWZlK _1BLPMq']\"):\n",
    "        Rating.append(i.text)\n",
    "    \n",
    "    for i in driver.find_elements(By.XPATH,\"//p[@class='_2-N8zT']\"):\n",
    "        Review_summary.append(i.text)\n",
    "    \n",
    "    for i in driver.find_elements(By.XPATH,\"//div[@class='t-ZTKy']/div/div\"):\n",
    "        Full_review.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "11634e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190 190 190\n"
     ]
    }
   ],
   "source": [
    "print(len(Rating),len(Review_summary),len(Full_review))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "79e258ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_summary</th>\n",
       "      <th>Full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Best and amazing product.....phone looks so pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>i11 is worthy to buy, too much happy with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Value-for-money</td>\n",
       "      <td>Just got this iphone 11\\nAnd it is most powerf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money❤️❤️\\nIts awesome mobile phone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It is just awesome mobile for this price from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Amazing camera quality as expected, battery al...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating      Review_summary  \\\n",
       "0       5           Fabulous!   \n",
       "1       5      Classy product   \n",
       "2       5   Worth every penny   \n",
       "3       4     Value-for-money   \n",
       "4       5    Perfect product!   \n",
       "..    ...                 ...   \n",
       "95      4         Good choice   \n",
       "96      5    Perfect product!   \n",
       "97      5    Perfect product!   \n",
       "98      5  Highly recommended   \n",
       "99      5  Highly recommended   \n",
       "\n",
       "                                          Full_review  \n",
       "0   This is my first iOS phone. I am very happy wi...  \n",
       "1   Best and amazing product.....phone looks so pr...  \n",
       "2   i11 is worthy to buy, too much happy with the ...  \n",
       "3   Just got this iphone 11\\nAnd it is most powerf...  \n",
       "4   It’s a must buy who is looking for an upgrade ...  \n",
       "..                                                ...  \n",
       "95  So far it’s been an AMAZING experience coming ...  \n",
       "96  Value for money❤️❤️\\nIts awesome mobile phone ...  \n",
       "97  It is just awesome mobile for this price from ...  \n",
       "98  iphone 11 is a very good phone to buy only if ...  \n",
       "99  Amazing camera quality as expected, battery al...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Review = pd.DataFrame({})\n",
    "Review['Rating'] = Rating[:100]\n",
    "Review['Review_summary'] = Review_summary[:100]\n",
    "Review['Full_review'] = Full_review[:100]\n",
    "Review\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102fec70",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price\n",
    "\n",
    "\n",
    "As shown in the below image, you have to scrape the above attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "f439103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\Yashika\\OneDrive\\Desktop\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "e842be22",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "970fa275",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "designation.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "91321af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "ff3ad86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_btn=driver.find_element(By.XPATH,\"//div[@class='_3OO5Xc']/input\")\n",
    "input_btn.send_keys('sneakers')\n",
    "\n",
    "# clicking the search button using xpath function \n",
    "btn=driver.find_element(By.XPATH,\"//button[@class='L0Z3Pu']\")\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "131ece08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url=driver.find_elements(By.XPATH,\"//nav[@class='yFHi8N']//a\")\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "afcde6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands=[] #empty list\n",
    "for i in page_url:\n",
    "    driver.get(i)\n",
    "    brand_tags=driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "    for i in brand_tags:\n",
    "        brands.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f1991417",
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_description=[] #empty list\n",
    "for i in page_url:\n",
    "    driver.get(i)\n",
    "    des_tags=driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\")\n",
    "    for i in des_tags:\n",
    "        pro_description.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "4f52825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "price=[] #empty list\n",
    "for i in page_url:\n",
    "    driver.get(i)\n",
    "    pri_tags=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "    for i in pri_tags:\n",
    "        price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "5328e38f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Brand, Product description, Price]\n",
       "Index: []"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sneakers=pd.DataFrame({})\n",
    "sneakers['Brand']=brands[:100]\n",
    "sneakers['Product description']=pro_description[:100]\n",
    "sneakers['Price']=price[:100]\n",
    "sneakers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118fcb05",
   "metadata": {},
   "source": [
    "# Q7: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. \n",
    "Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "5d65cb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Yashika\\OneDrive\\Desktop\\chromedriver.exe\")\n",
    "driver.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "9d5e0da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(2)\n",
    "\n",
    "driver.get(' https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "6028f9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//input[@id=\"twotabsearchtextbox\"]').send_keys('Laptop')\n",
    "time.sleep(2)\n",
    "\n",
    "#clicking the search button\n",
    "\n",
    "driver.find_element(By.XPATH,'//input[@id=\"nav-search-submit-button\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "6a35ed87",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,\"//*[@id='p_n_feature_thirteen_browse-bin/12598163031']/span/a\").click()\n",
    "time.sleep(4)\n",
    "\n",
    "driver.find_element(By.XPATH,\"//*[@id='p_n_feature_thirteen_browse-bin/16757432031']/span/a\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "851a401f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel Core i7 13.3\" FHD ...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>94,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LG Gram14 Intel EVO-[12th Gen Corei7/Win11/16G...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>84,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS Vivobook 14, Intel Core i7-1165G7 11th Ge...</td>\n",
       "      <td>2.8 out of 5 stars</td>\n",
       "      <td>56,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acer Nitro 5 Gaming Laptop Intel core i7 11th ...</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "      <td>78,106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS Vivobook Pro 16, Intel Core i9 11th Gen, ...</td>\n",
       "      <td>3.8 out of 5 stars</td>\n",
       "      <td>89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 12th Gen Intel Core i7 1...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Victus Gaming Latest 12th Gen Intel Core i7...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo IdeaPad Gaming 3 Intel Core i7-12700H 1...</td>\n",
       "      <td>3.7 out of 5 stars</td>\n",
       "      <td>99,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...</td>\n",
       "      <td>3.9 out of 5 stars</td>\n",
       "      <td>94,630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo ThinkPad E14 Intel Core i7 12th Gen 14\"...</td>\n",
       "      <td>3.5 out of 5 stars</td>\n",
       "      <td>1,02,490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title             Ratings  \\\n",
       "0  Fujitsu UH-X 11th Gen Intel Core i7 13.3\" FHD ...  4.3 out of 5 stars   \n",
       "1  LG Gram14 Intel EVO-[12th Gen Corei7/Win11/16G...  4.0 out of 5 stars   \n",
       "2  ASUS Vivobook 14, Intel Core i7-1165G7 11th Ge...  2.8 out of 5 stars   \n",
       "3  Acer Nitro 5 Gaming Laptop Intel core i7 11th ...  4.5 out of 5 stars   \n",
       "4  ASUS Vivobook Pro 16, Intel Core i9 11th Gen, ...  3.8 out of 5 stars   \n",
       "5  Lenovo IdeaPad Slim 5 12th Gen Intel Core i7 1...  4.2 out of 5 stars   \n",
       "6  HP Victus Gaming Latest 12th Gen Intel Core i7...  4.3 out of 5 stars   \n",
       "7  Lenovo IdeaPad Gaming 3 Intel Core i7-12700H 1...  3.7 out of 5 stars   \n",
       "8  HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...  3.9 out of 5 stars   \n",
       "9  Lenovo ThinkPad E14 Intel Core i7 12th Gen 14\"...  3.5 out of 5 stars   \n",
       "\n",
       "      Price  \n",
       "0    94,990  \n",
       "1    84,500  \n",
       "2    56,990  \n",
       "3    78,106  \n",
       "4    89,990  \n",
       "5    79,990  \n",
       "6    84,990  \n",
       "7    99,990  \n",
       "8    94,630  \n",
       "9  1,02,490  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Title=[]\n",
    "Ratings=[]\n",
    "Price=[]\n",
    "\n",
    "#scrapping the title\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]'):\n",
    "    Title.append(i.text)\n",
    "    Title=Title[:10]\n",
    "\n",
    "#scrapping the rating\n",
    "\n",
    "Rating=driver.find_elements(By.XPATH,'//div[@class=\"a-row a-size-small\"]/span[1]')  \n",
    "for i in Rating:\n",
    "    Ratings.append(i.get_attribute('aria-label'))\n",
    "    Ratings=Ratings[:10]\n",
    "    \n",
    "#scrapping the Price\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]'):\n",
    "    Price.append(i.text)\n",
    "    Price=Price[:10]\n",
    "    \n",
    "#creating the dataframe\n",
    "Amazon_laptop={'Title':Title,'Ratings':Ratings,'Price':Price}\n",
    "Amazon_laptop=pd.DataFrame(data=Amazon_laptop)\n",
    "Amazon_laptop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5a7216",
   "metadata": {},
   "source": [
    "# Que - 8 Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "The above task will be done in following steps:\n",
    "1. First get the webpagehttps://www.azquotes.com/\n",
    "2. Click on TopQuotes\n",
    "3. Than scrap a) Quote b) Author c) Type Of Quotes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "cf124def",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\Yashika\\OneDrive\\Desktop\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "5b1839ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.azquotes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "62469e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "5792f5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait = WebDriverWait(driver, 30)\n",
    "top_quotes_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//a[contains(text(), 'Top Quotes')]\")))\n",
    "top_quotes_button.click()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb43ee5",
   "metadata": {},
   "source": [
    "#quote = []\n",
    "author  = []\n",
    "type_of_quotes = []\n",
    "\n",
    "for i in range(1,20):\n",
    "    \n",
    "    for i in driver.find_elements(By.XPATH,\"//a[@class='title']\"): \n",
    "        quote.append(i.text)\n",
    "    \n",
    "    for i in driver.find_elements(By.XPATH,\"//div[@class='author']\"):\n",
    "        author.append(i.text)\n",
    "    \n",
    "    for i in driver.find_elements(By.XPATH,\"//div[@class='tags']\"):\n",
    "        type_of_quotes.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "aac83dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900 1900 1900\n"
     ]
    }
   ],
   "source": [
    "print(len(quote),len(author),len(type_of_quotes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "6b5de533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quote</th>\n",
       "      <th>author</th>\n",
       "      <th>type_of_quotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>When the going gets weird, the weird turn pro.</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Music, Sports, Hunting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>When a train goes through a tunnel and it gets...</td>\n",
       "      <td>Corrie Ten Boom</td>\n",
       "      <td>Trust, Encouraging, Uplifting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>If you think you are too small to make a diffe...</td>\n",
       "      <td>Dalai Lama</td>\n",
       "      <td>Inspirational, Funny, Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>God doesn't require us to succeed, he only req...</td>\n",
       "      <td>Mother Teresa</td>\n",
       "      <td>Success, God, Mother</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Change your thoughts and you change your world.</td>\n",
       "      <td>Norman Vincent Peale</td>\n",
       "      <td>Inspirational, Motivational, Change</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 quote                author  \\\n",
       "0    The essence of strategy is choosing what not t...        Michael Porter   \n",
       "1    One cannot and must not try to erase the past ...            Golda Meir   \n",
       "2    Patriotism means to stand by the country. It d...    Theodore Roosevelt   \n",
       "3    Death is something inevitable. When a man has ...        Nelson Mandela   \n",
       "4    You have to love a nation that celebrates its ...          Erma Bombeck   \n",
       "..                                                 ...                   ...   \n",
       "995     When the going gets weird, the weird turn pro.    Hunter S. Thompson   \n",
       "996  When a train goes through a tunnel and it gets...       Corrie Ten Boom   \n",
       "997  If you think you are too small to make a diffe...            Dalai Lama   \n",
       "998  God doesn't require us to succeed, he only req...         Mother Teresa   \n",
       "999    Change your thoughts and you change your world.  Norman Vincent Peale   \n",
       "\n",
       "                               type_of_quotes  \n",
       "0    Essence, Deep Thought, Transcendentalism  \n",
       "1                   Inspiration, Past, Trying  \n",
       "2                         Country, Peace, War  \n",
       "3          Inspirational, Motivational, Death  \n",
       "4                4th Of July, Food, Patriotic  \n",
       "..                                        ...  \n",
       "995                    Music, Sports, Hunting  \n",
       "996             Trust, Encouraging, Uplifting  \n",
       "997              Inspirational, Funny, Change  \n",
       "998                      Success, God, Mother  \n",
       "999       Inspirational, Motivational, Change  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Review = pd.DataFrame({})\n",
    "Review['quote'] = quote[:1000]\n",
    "Review['author'] = author[:1000]\n",
    "Review['type_of_quotes'] = type_of_quotes[:1000]\n",
    "Review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9451c1b",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to display list of respected former Prime Ministers of India\n",
    "(i.e. Name, Born-Dead, Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.jagranjosh.com/\n",
    "2. Then You have to click on the GK option\n",
    "3. Then click on the List of all Prime Ministers of India\n",
    "4. Then scrap the mentioned data and make theDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "1f0c2f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\Yashika\\OneDrive\\Desktop\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "429f8502",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.jagranjosh.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "65a4a792",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "f35e1325",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,\"//a[contains(text(), 'GK')]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "95808516",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait = WebDriverWait(driver, 10)\n",
    "prime_minister_link = wait.until(EC.visibility_of_element_located((By.XPATH, \"//a[contains(text(), 'List of all Prime Ministers of India')]\")))\n",
    "\n",
    "# click on the \"List of all Prime Ministers of India\" link\n",
    "prime_minister_link.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "8bace467",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = []\n",
    "born_dead = []\n",
    "term_of_office = []\n",
    "remarks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "2c3a2a7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "MaxRetryError",
     "evalue": "HTTPConnectionPool(host='localhost', port=56925): Max retries exceeded with url: /session/33596493f0ba1a16ecb7e343e34c0778/elements (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016E3EDB24C0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[0;32m    175\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dns_host, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kw\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py:95\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgetaddrinfo returns an empty list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 85\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sock\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:398\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 398\u001b[0m         conn\u001b[38;5;241m.\u001b[39mrequest(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhttplib_request_kw)\n\u001b[0;32m    400\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py:239\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers)\u001b[0m\n\u001b[0;32m    238\u001b[0m     headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _get_default_user_agent()\n\u001b[1;32m--> 239\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mHTTPConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:1285\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1285\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:1331\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1330\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1331\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:1280\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1280\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:1040\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1040\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1043\u001b[0m \n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:980\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m--> 980\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py:205\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 205\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_conn(conn)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m e\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x0000016E3EDB24C0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [288]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m20\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m//td[@class=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-center\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m]/a\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m: \n\u001b[0;32m      4\u001b[0m         name\u001b[38;5;241m.\u001b[39mappend(i\u001b[38;5;241m.\u001b[39mtext)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m driver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mXPATH,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m//td[@class=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-center\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]/text()\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:892\u001b[0m, in \u001b[0;36mWebDriver.find_elements\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    888\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m value\n\u001b[0;32m    890\u001b[0m \u001b[38;5;66;03m# Return empty list if driver returns null\u001b[39;00m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;66;03m# See https://github.com/SeleniumHQ/selenium/issues/4555\u001b[39;00m\n\u001b[1;32m--> 892\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:442\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m    440\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[1;32m--> 442\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:294\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    292\u001b[0m data \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mdump_json(params)\n\u001b[0;32m    293\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:316\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    313\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[1;32m--> 316\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\request.py:78\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[0;32m     75\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[0;32m     76\u001b[0m     )\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_body(\n\u001b[0;32m     79\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[0;32m     80\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\request.py:170\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    167\u001b[0m extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mupdate(headers)\n\u001b[0;32m    168\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[1;32m--> 170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kw)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\poolmanager.py:376\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    374\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 376\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, u\u001b[38;5;241m.\u001b[39mrequest_uri, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    378\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:813\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[0;32m    810\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    811\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    812\u001b[0m     )\n\u001b[1;32m--> 813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    814\u001b[0m         method,\n\u001b[0;32m    815\u001b[0m         url,\n\u001b[0;32m    816\u001b[0m         body,\n\u001b[0;32m    817\u001b[0m         headers,\n\u001b[0;32m    818\u001b[0m         retries,\n\u001b[0;32m    819\u001b[0m         redirect,\n\u001b[0;32m    820\u001b[0m         assert_same_host,\n\u001b[0;32m    821\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    822\u001b[0m         pool_timeout\u001b[38;5;241m=\u001b[39mpool_timeout,\n\u001b[0;32m    823\u001b[0m         release_conn\u001b[38;5;241m=\u001b[39mrelease_conn,\n\u001b[0;32m    824\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    825\u001b[0m         body_pos\u001b[38;5;241m=\u001b[39mbody_pos,\n\u001b[0;32m    826\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw\n\u001b[0;32m    827\u001b[0m     )\n\u001b[0;32m    829\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[0;32m    830\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:813\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[0;32m    810\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    811\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    812\u001b[0m     )\n\u001b[1;32m--> 813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    814\u001b[0m         method,\n\u001b[0;32m    815\u001b[0m         url,\n\u001b[0;32m    816\u001b[0m         body,\n\u001b[0;32m    817\u001b[0m         headers,\n\u001b[0;32m    818\u001b[0m         retries,\n\u001b[0;32m    819\u001b[0m         redirect,\n\u001b[0;32m    820\u001b[0m         assert_same_host,\n\u001b[0;32m    821\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    822\u001b[0m         pool_timeout\u001b[38;5;241m=\u001b[39mpool_timeout,\n\u001b[0;32m    823\u001b[0m         release_conn\u001b[38;5;241m=\u001b[39mrelease_conn,\n\u001b[0;32m    824\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    825\u001b[0m         body_pos\u001b[38;5;241m=\u001b[39mbody_pos,\n\u001b[0;32m    826\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw\n\u001b[0;32m    827\u001b[0m     )\n\u001b[0;32m    829\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[0;32m    830\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:813\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[0;32m    810\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    811\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    812\u001b[0m     )\n\u001b[1;32m--> 813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    814\u001b[0m         method,\n\u001b[0;32m    815\u001b[0m         url,\n\u001b[0;32m    816\u001b[0m         body,\n\u001b[0;32m    817\u001b[0m         headers,\n\u001b[0;32m    818\u001b[0m         retries,\n\u001b[0;32m    819\u001b[0m         redirect,\n\u001b[0;32m    820\u001b[0m         assert_same_host,\n\u001b[0;32m    821\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    822\u001b[0m         pool_timeout\u001b[38;5;241m=\u001b[39mpool_timeout,\n\u001b[0;32m    823\u001b[0m         release_conn\u001b[38;5;241m=\u001b[39mrelease_conn,\n\u001b[0;32m    824\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    825\u001b[0m         body_pos\u001b[38;5;241m=\u001b[39mbody_pos,\n\u001b[0;32m    826\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw\n\u001b[0;32m    827\u001b[0m     )\n\u001b[0;32m    829\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[0;32m    830\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:785\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, (SocketError, HTTPException)):\n\u001b[0;32m    783\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m--> 785\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    788\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n\u001b[0;32m    790\u001b[0m \u001b[38;5;66;03m# Keep track of the error for the retry warning.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    581\u001b[0m new_retry \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew(\n\u001b[0;32m    582\u001b[0m     total\u001b[38;5;241m=\u001b[39mtotal,\n\u001b[0;32m    583\u001b[0m     connect\u001b[38;5;241m=\u001b[39mconnect,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    588\u001b[0m     history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[0;32m    589\u001b[0m )\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    594\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_retry\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='localhost', port=56925): Max retries exceeded with url: /session/33596493f0ba1a16ecb7e343e34c0778/elements (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016E3EDB24C0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))"
     ]
    }
   ],
   "source": [
    "for i in range(1,20):\n",
    "    \n",
    "    for i in driver.find_elements(By.XPATH,'//td[@class=\"text-center\"]/a'): \n",
    "        name.append(i.text)\n",
    "    \n",
    "    for i in driver.find_elements(By.XPATH,'//td[@class=\"text-center\"]/text()'):\n",
    "        born_dead.append(i.text)\n",
    "    \n",
    "    for i in driver.find_elements(By.XPATH,'//td[@class=\"text-center\"]'):\n",
    "        term_of_office.append(i.text)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3246dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
